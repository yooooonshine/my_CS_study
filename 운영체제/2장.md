* \# 운영체제로 제어권이 넘어가는 세가지 경우
	* 1. 인터럽트 발생
	* 2. page fault 발생
	* 3. 시스템콜 호출
  
* ## 2.1 프로세스
	* 프로세스: 
		* 실행중인 프로그램을 추상화 한 것. , 논리적으로 작성된 프로그램을, 데이터를 가져와 행하는 것
		* 프로세스는 job, task, sequencial process와 동일어이다.
	* 프로그램:
		* 실행 파일 그 자체이고
		* 정적이다.
		  
	* 병렬적인 활동을 다루기 위한 모델
		* 의사병렬성(pseudoparrallelism): 
			* 한 cpu가 한 프로세스에서 다른 프로세스로 빠르게 넘어가면서 각 프로세스를 짧은 시간동안 번갈아 가면서 수행해, 병렬 수행하는 거 처럼 보이게 하는 것.
			* 이는 실제 cpu가 여러개인 다중처리기 시스템과 구분된다.
		* 다중처리기(multiprocessor)
			* 실제 cpu가 여러개라서 한 번에 여러 프로세스르 다룬다.
			  
	* \# 다른 fault와 다르게 page fault는 수정가능하기에 blocked 되지 않고 os로 제어권이 넘어가게 된다.
	  
	* page fault
		* 메인 메모리의 용량으로 인해 모든 프로세스를 메모리에 두지 않고, 디스크에 보관하였다가 필요한 것을 꺼내쓰는데, 이 떄 메모리에서 사용하려는 프로세스가 존재하지 않는 상황이 page fault이다.
	* PID(process id)
		* 프로세스를 식별하는 고유 id로 부모와 자식은 다른 PID를 갖는다.
		  
	* #### 주소공간
		* ![[Pasted image 20231017162151.png]]
		* 이를 보면 한 주소 공간 안에 코드, stack, 데이터가 들어가 있다.
		* 스택은 동적할당을 위한 공간
		  
	* ### 용어 정리
		* #### PID
			* process id는 프로세스를 식별한다. 
		* #### PT(process table)
			* 프로세스는 process table의 entries들로 나타나 진다.
				* 즉 여기서 entries는 프로세스에 대한 모든 정보를 포함한다. 
				* 즉 프로세스 테이블 안에 pbc가 있다.
		  
		  
	* #### 2.1.1 프로세스 모델
		* 모든 소프트웨어는 순차 프로세스(=sequential process == process)로 구성되어 있고,
		* 각 프로세스는 pc(program counter), 레지스터, 변수들을 포함한다.
			* 프로세스가 포함하는 것은
				* 주소공간
				* 실행 코드
				* 데이터
				* 스택포인터(sp)
				* 프로그램 카운터(pc)
				* 레지스터
				* 시스템 소스(파일)
		* 한 cpu는 한 프로세스만을 처리하지만 ,빠르게 왔다갔다해서 동시에 처리하는 것처럼 보이는 것.
		* 다중프로그래밍(multi programming)
			* 프로그램 사이를 빨리 전환하는 것.
		* 특정 프로세스가 시작될 떄 논리적인 프로그램 카운터는 실제(물리적인) 프로그램 카운터에 적재 되어야 한다.
		* 프로세스는 프로그램, 입력, 출력, 상태를 가진다.
		* 또한 하나의 processor(처리기)에 여러 프로세스가 들어올 수 있다.
		* processor에 무엇이 들어올 지는 스케줄링 알고리즘을 따른다.
		  
		  
		  
	* #### 2.1.2 프로세스 생성
		* 매우 간단한 시스템은 시스템이 기동할 때 모든 프로세스를 만들어지도록 하나,
		* 복잡한 시스템은 운영 도중에 필요한 프로세스를 생성하고 종료 해야한다.
		  
		* ##### 프로세스 생성을 유발하는 네 가지 이벤트
			* 1. 시스템 초기화
			* 2. 실행중인 프로세스가 프로세스 생성 시스템 콜을 호출했을 경우
			* 3. 배치 작업의 시작, 즉 순차적으로 프로세스를 생성하고 종료
			* 4. 사용자가 프로세스 생성 요청
			  
		* ##### 전위 프로세스와 백그라운드 프로세스
			* 전위(foreground) 프로세스란 사용자와 소통하고, 이들을 위해 작업을 수행하는 프로세스
			* 백그라운드 프로세스(=demon)은 사용자와 연관되어 있지 않고, 미리 정해진 일을 하는 프로세스, 혹은 대기하다가 외부에서 요청이 들어오면 일을 하는 프로세스
			  
		* 프로세스가 프로세스를 생성하려면 시스템 콜을 해야한다. 왜냐면 생성은 운영체제가 하는 일인데, 프로세스가 운영체제 내부에서 돌아가는 게 아니니까
		* 마이크로 소프트 windows의 경우 프로세스가 시작할 때 윈도우를 갖게 된다. 윈도우는 프로세스를 수행한다.
		* 모든 새로운 프로세스는 기존의 프로세스가 프로세스 생성 시스템 콜을 불러서 생성한다.
		* 호출되는 프로세스는 1. 기존 프로세스 2. 키보드등의 시스템 프로세스, 3. 배치 관리자 프로세스 중 하나가 호출한다.
		* UNIX의 경우 새로운 프로세스는 fork를 통해 기존의 프로세스를 그대로 복사하면서 시작된다. 그럼 동일한 메모리 내용, 같은 환경 문자열, 동일한 열린 파일들을 가진다.
		* 이후 execve를 통해 생성된 프로세스를 변경하고 프로그램을 수행한다.
		* 이는 결국 fork, execve라는 두가지 단계를 거치는 데, 이 중간에 자신의 파일 디스크럽터를 조작하여, 표준입력, 표준출력, 표준오류의 io방향을 변경할 수 있다.
		  
		  * ### UNIX process creation
			  * 유닉스에서는 fork() 명령어를 통해 프로세스를 만든다.
			    
			  * #### fork()시스템 과정
				  * PCB를 새로 만들고 부모의 것으로 초기화 한다.
				  * 주소공간을 새로 만들고 부모의 것으로 초기화한다.
				  * 커널 소스를 부모의 것으로 초기화한다.
				  * 이 PCB를 ready queue에 넣어 실행되기를 기다린다.
				  * ![[Pasted image 20231017163530.png]]
				  * fork 명령어는 자식이 부모의 코드도 그대로 배끼므로 두 번 실행된다.
				  * 부모의 fork에서는 자식 pid가 리턴되고
				  * 자식프로세스 코드 안의 fork에서는 0이 리턴된다.
				  * 이를 이용해 if, else문으로 부모와 자식에서 각각 실행될 코드를 구별할 수 있다.
				    
			* 이렇게 fork를 하면 자식 프로세스는 exec() 시스템 콜을 통해 자식 프로세스가 실행할 프로그램을 가져온다.
			  
			* #### exec()
				* ![[Pasted image 20231017164820.png]]
				* 과정
					* exec 시스템 콜이 발생하면 현재 진행하던 프로세스를 멈춘다.
					* 새로 생긴 주소공간에 prog(프로그램)의 주소공간을 가져온다.
					* 이외의 값들을 초기화한다.
					* PCB를 ready queue에 넣는다.
		  
		* ##### 파일 디스크럽터(fd)
			* 프로세스에서 열린 파일의 목록을 관리하는 테이블의 인덱스
			* 유닉스에서 모든 것은 파일이라고 한다. 이런 파일들을 접근할 때 파일 디스크럽터를 이용한다.
		* 이렇게 생성된 부모와 자식 프로세스는 다른 주소를 갖는다. 즉 한쪽이 변경되어도 다른 쪽에 영향을 주지 않는다.
		  
		* ##### 부모와 자식 프로세스
			* 1. 주소는 동일하지 않다.
			* 2. 파일은 동일한 자원들을 공유한다.
			* 3. 자식의 초기 주소 공간(프로그램, 데이터, 스택)은 부모 프로세스를 복사, 하지만 분명히 다른 주소 공간
			* 4. 읽기만 가능한 메모리는 공유될 수 있지만, 쓰기가능한 메모리는 공유되지 않는다.
			* 5. 프로그램 내용은 동일하다.
			  
			  
			  
	* #### 2.1.3 프로세스 종료
		* 종료의 조건
			* 1. 정상적인 종료(자발적)
				* 예로 컴파일러가 컴파일 완료하고 exit 등으로 끝났음을 알림
			* 2. 오류종료(자발적)
				* 컴파일 하기로 한 프로그램 파일이 없을 경우
			* 3. 치명적인 오류(비자발적)
				* 프로세스에 의해 유발된 오류, 예로 0으로 나누기, 존재하지 않은 메모리 접근등
			* 4. 다른 프로세스에 의해 종료(비자발적)
				* kill 명령어(한 프로세스가 다른 프로세스 종료할 때 사용, 단 권한 필요)
				  
		* ##### Process Termination
			* 정상적인 종료
				* exit() 시스템 콜을 호출시킨다.
				* 프로세스의 마지막 statement 수행 후, 자발적으로 exit() 호출하여 프로세스를 종료시킨다.
				* 혹은 main함수가 리턴되면, 이 때도 exit()가 호출된다.
			* 비정상적인 종료
				* abort() 시스템 콜을 호출시킨다.
				* 부모프로세스가 종료되면, 자식도 exit()
				* 부모프로세스에서 자식 프로세스를 강제 종료 시킨다
				* 사용자가 kill 명령어를  통해 프로세스를 종료 시킨다.
			* 어떻게 종료되었던 무관하게 결국 모든 open된 descriptor를 close하고, 메모리를 비운다.
				  
				  
	* #### 2.1.4 프로세스 계층 구조
		* 부모, 자식 프로세스에서  자식 프로세스는 단 하나의 부모 프로세스만 가지고 부모 프로세스는 여러 자식 프로세스를 가질 수 있다.
		* unix
			* unix에서는 init이라는 특별 프로세스가 자신에게 전달된 터미널 수 만큼 프로세스를 생성한다. 이 프로세스들은 로그인을 기다리며, 로그인 되면, 각자 명령을 받아들이는 쉘을 실행하면서 여러 프로세스를 생성하게 된다.
			* 즉 모든 프로세스는 init에 뿌리를 둔다.
		* windows
			* windows에서는 계층 구조가 없다.
			  
			  
	* #### 2.1.5 프로세스 상태
		* ![[Pasted image 20231009104728.png]]
			* running은 프로세스가 진행중이다.
			* ready는 프로세스가 실행가능하지만 사용할 수 없는 cpu가 없어서 일시적 대기
			* blocked은 cpu가 있어도 프로세스를 수행할 수 없는 상태.
			* 상태 전이
				* 1은 프로세스가 수행을 지속할 수 없음을 운영체제가 발견할 경우 혹은 프로세스 스스로 pause할 수도 있다
				* 2,3은 프로세스 스케쥴러에 의하여 발생한다. 2는 프로세스가 충분히 오래동안 수행했다 판단될 떄, 스케줄러가 다른 프로세스에게 cpu를 할당. 3은 다른 프로세스들이 충분히 할당되었고 다시 cpu를 할당해야겠다 판단되었을떄
				* 4는 프로세스가 기다리던 외부 이벤트가 발생했을 경우, 일단 ready상태로 가며, 만약 cpu가 비어있으면 바로 3으로 동작한다.
		* ![[Pasted image 20231009112040.png]]
			* 프로세스의 가장 하위 계층은 스케쥴러이다. 그 위에 다른 프로세스들이 존재한다.
			* 스케줄러는 모든 인터럽트 처리와 프로세스를 시작하고 중단하는 일을 한다.
			  
		* ![[Pasted image 20231018165051.png]]
			* create
				* 이건 fork 등으로 생긴 프로세스가 exec을 통해 pcb를 ready queue로 넣은 상태
			* I/O, page fault, etc
				* 이러한 경우로 운영체제로 제어권이 넘어가, 프로세스가 block되며,
				* 이 때 io는  read 시스템 콜을 호출해 io컨트롤러를 동작시킨다.
			* 만약 한 프로세스가 무한루프를 돌면 cpu를 독점하게 된다. 근데 os는 이게 무한루프인 줄 모르므로, 주기적으로 interrupt를 통해 프로세스를 끌어 내린다. 
			  
			  
	* #### 2.1.6 프로세스의 구현
		* ##### 프로세스 테이블,=프로세스 제어블록(=PCB)
			* ![[Pasted image 20231009112654.png]]
			* 프로세스 모델을 구현하기 위해(주소공간, 자원 집합등) 운영체제는 프로세스마다 프로세스테이블을 운영한다.
			* pcb에는 프로그램 카운터, 스택 포인터, 메모리할당, 열린 파일들의 상태, 스케줄링 정보, 프로세스가 준비 혹은 대기상태로 들어갈 때 저장되어야할 모든 정보 등을 저장한다.
		* ##### 하나의 cpu에서 다수의 순차 프로세스들이 유지되는 과정
			* 각각의 io마다 인터럽트 벡터(인터럽트 서비스 루틴(프로시져)을 가리키는 인터럽트 벡터 테이블에서 한 열)와 연관되어 있다.
			* 프로세스3이 수행중일때 디스크 인터럽트가 발생한다면
				* 인터럽트 하드웨어가 프로세스3의 pc,psw, 레지스터등을 스택에 저장한다.
				* 이후 인터럽트 벡터가 지시하는 인터럽트 서비스 루틴(소프트웨어)가 작동
				* 서비스 루틴에 의하여, 스택에 저장된 프로세스 정보를 프로세스의 pcb에 저장하고, 스택을 제거한다. 
				* 이떄 스택 포인터는 프로세스 핸들러에 의해 사용되는 임시 스택을 가리키도록 설정.
				* 위의 동작들은 어셈블리 언어로 처리되며, 저장같은 행동은 모든 인터럽트에 공통적을 사용된다.
				* 이후 인터럽트 나머지 작업(저장 이후의 작업, 보통 c언어로 작성됨)을 수행하는 프로시듀어를 호출한다. 
				* 이 프로시듀어는 몇몇 프로세스(인터럽트가 원하는 프로세스)를 준비 상태로 만들 수 있으며,
				* 이 후 스케줄러가 호출되어 어떤 프로세스를 수행할지 결정
				* 결정을 마치면 새로운 프로세스의 레지스터와 메모리를 적재하고 실행
				  
		* ##### Context switch
			* 한 프로세스에서 다른 프로세스로 바뀌는 것은 context switch라고 한다.
		* ![[Pasted image 20231009203427.png]]
		* 왜 save state가 startio 사이에서 발생? 이는 정확하지 않다.
		* 일단 확실한 것은 os로 시스템 호출되었을 때,  꼭 모두 io에 접근하는 것은 아니고, 일부 처리만 os에서 하고 끝날 수 있다. 그럼 context switch(다른 프로세스로 전환)이 안 일어나므로, 기존 프로세스를 저장할 필요가 없다. 따라서 일부 처리하고 인터럽트 핸들러가 io에 접근해야 한다 판단하면 그때서야 pcb에 저장하는 것.
		* read도 context switch발생 안 할 수 있다.
		* read일 때도 main에서 돌아가던 프로세스는 running 상태이다. io 발생하는 게 확실시 되면 그 때서야 block 된다.
		* io 끝나면 interrupt 발생하여 A프로세스가 ready queue로 들어가고, 이 때 스케쥴링한다.
		  
		  
	* #### 2.2 스레드(thread, = lightweightprocess)
		* 스레드의 장점
			* 1. 다수의 프로세스를 사용하여 해결할 수 없는 문제를 해결해준다.
				* 한 프로세스 내에서 다수의 프로세스인 척 병렬적으로 제어 흐름을 가지는 것
				* 스레드들은 주소공간과, 프로세스 실행동안 모든 데이터를 공유한다.
				* 이는 다수의 프로세스를 사용하여 해결할 수 없는 문제를 해결 해준다.
			* 2.스레드는 프로세스 생성 제거보다 훨 빠르다.
			* 3.많은 연산 많은 io가 동시 존재하는 경우 스레드는 이러한 동작들을 겹치도록(유사병렬적으로) 수행할 수 있어 응용속도를 향상시킬 수 있다.
			* 4.병렬성을 제공하는 다수의 CPU를 가진 시스템에서 유용하다.
		* 예로 한 워드 프로그램(프로세스)를 사용하면서, 날라가지 않도록 스레드를 운영해 주기적으로 저장하게 할 수도 있다. 
		* 여기서 왜 다른 프로세스로 안하고 스레드로 하냐면, 공통의 데이터를 대상을 하기에
		  
		* ##### Finite-state marchine(유한 상태 기계)
			* 이는 각 연산마다 , 저장된 상태, 그리고 이 저장된 상태를 변경할 수 있는 이벤트가 존재하는 설계
			* 예로 병렬이 아닌 단일 스레드를 사용한다면, 차례차례 수행할 수 도 있지만, 사용하려는 데이터가 메모리에 없고 디스크에 있다면 기다려야한다.
			* 이를 해결하고자, 현재 disk에서 데이터를 가져오려는 스레드 상태를 저장하고, 다른 스레드를 처리하다가, 디스크에서 정보를 가져왔으면 스레드 재개, 이는 blocking이다.
		* 참고: blocking과 nonblocking
			* blocking
				* 이는 한 작업이 수행되는 동안에는 다른 작업은 진행하지 못하고 대기
			* nonblocking
				* 특정 작업이 수행중이더라도 이와 무관하게 바로 다음 작업 수행시키는 방식
				  
		* 스레드
			* 스레드는 cpu에서 실행되도록 스케쥴되는 객체고, 프로세스는 정보를  한 군데로 모은 것이다.
			* 스레드는 다음에 실행할 명령을 가리키는 프로그램  카운터를 가진다.
			* 작업변수를 저장하는 레지스터를 가진다.
			* 스택을 가진다.
			* 스레드는 다른 스레드와 주소공간과, 데이터를 공유한다.
			* 한 프로세스 내에서 스레드들은 동일한 주소 공간 전역 변수를 가지며, 즉 주소 공간 내 모든 메모리 주소를 접근할 수 있기에, 다른 스레드의 스택을 읽고, 기록하고 지울 수 있다.
			* 이를 막지않은 이유는 스레드들은 서로 협력하는 존재이기에, 서로를 막는 것은 불필요하기 때문이다.
			* 스레드는 프로세스와 동일하게 실행, 대기, 준비, 종료 상태를 가질 수 있다.
			* 프로세스 내에서 스레드가 작동하는 것이므로, 스레드가 실행되면 마찬가지로 이는 cpu를 점유하는 것
			* 각 스레드들은 다른 스택을 가져야한다.
				* ![[Pasted image 20231018191857.png]]
				* 스택에는 프로시듀어의 지역변수, 복귀주소를 저장해 놓는데, 이를 공유한다면 꼬일 수 있다.
				
			  
		* 다중 스레딩(multithreading)
			* 다수의 스레드가 하나의 프로세스에서 수행되는 것이 가능한 상황
			  
		* 스레드 명령어
			* thread_create
				* 이는 라이브러리 프로시듀어이고, 스레드를 생성한다. 매개변수로는 스레드 이름이 있다.
				* 스레드는 같은 공간에서 실행되므로, 스레드만의 주소공간을 갖는 일은 불필요하다.
				* 스레드는 계층관계(부모,자식)을 가질 수 있으며, 이 때 부모스레드는 자식 스레드의 스레드 식별자(thread identifier)를 갖게 된다.
			* thread_exit
				* 스레드를 종료시켜, 더 이상 스케줄 되지 않도록한다.
			* thread_join
				* 이 프로시듀어는 한 스레드가 끝날 때까지 호출한 스레드는 호출되지 않도록 한다.
				* 즉 특정 프로시듀어가 종료될 때까지 스레드는 블록된다.
			* thread_yield
				* 스레드가 자발적으로 cpu를 포기하여 다른 스레드가 실행될 수 있도록한다.
				* 스레드에는 clock interrupt가 없기에 매우 중요한 프로시듀어이다.
				  
		  * #### Posix 스레드
			  * 이를 Pthread라고 불리며, 스레드를 위한 표준이다.
			  * ![[Pasted image 20231018192836.png]]
			  * Pthread_craete는 함수의 리턴 값으로 스레드id가 리턴된다.
			  * Pthread_join은 스레드가 종료될 때까지 기다리는 데, 매개변수로 기다릴 스레드를 적어준다.
			  * Pthread_attr_init은  속성 구조체(스레드에 대한 정보를 가진 것)를 생성하고 필드들의 값을 설정한다.
		* ## 스레드를 구현하는 세가지 방법
			* 1. 사용자 공간  스레드(user level thread)
				* ![[Pasted image 20231018195541.png]]
				* 스레드를 사용자 공간에서 구현하여, 커널에서는 이를 모르게 한다.
				* 즉 커널 입장에서는 단일 스레드가 프로세스 내에서 진행하고 있는 거처럼 보인다.
				* 즉 스레드를 지원하지 않는 운영체제에서도 구현할 수 있다.
				* 런타임 시스템이 스레드를 관리한다. 런타임 시스템은 스레드 관리 프로시듀어(pthread등)의 모음이다.
				* 런타임 시스템 과정
					* 스레드가 다른 스레드의 종료를 기다리는 거와 같이, 스레드를 대기 상태로 만들지도 모르면 런타임 시스템을 호출한다.
					* 그럼 런타임 시스템은 반드시 스레드를 대기 상태가 되어야 하는 지 체크하고 그렇다하면, 스레드 테이블에 레지스터등을 저장한다.
					* 그 다음 스레드 스케줄러로 다음 스레드를 찾고, 새 스레드의 레지스터를 적재하고 돌린다.
				* Thread Table
					* 프로세스는 각 스레드를 위한 스레드 테이블을 가져야한다.
					* 스레드 테이블에는 스레드의 스택포인터, 프로그램 카운터,레지스터등 스레드를 위한 여러 속성을 갖고 있다.
				* 단점
					* 한 스레드가 시스템 콜을 하면, 프로세스 전체가 blocked 되므로, 다른 스레드들도 중단될 수 있다.
					* 스레드에 대한 클록 인터럽트가 없어서, 무한히 동작하는 스레드를 컨트롤할 수 가 없다.
					* 커널 스레드의 경우 cpu가 두개고, 비어있다면, 한 프로세스에 대한 두 스레드를, 두 cpu에서 동시에 돌릴 수 있지만, 유저레벨 스레드에서는 그게 불가능하다.
				* ##### jacket = wrapper
					* blocked 되면 안되므로, 시스템 콜이 호출될 지 미리 알 수 있으면 대응이 가능하다.
					* 이를 select 시스템 호출이 확인하여 있는 줄 알려준다.
					* read가 존재할 경우, 다른 스레드가 block되지 않을 경우에만 실행하고, 아니면 다른 스레드를 우선적으로 실행한다.
					* 이렇게 시스템 콜 주위에서 검사를 수행하는 코드를 자켓(래퍼)라고 한다.
			* 2. Os가 관리하는 스레드(kernel thread)
				* ![[Pasted image 20231018195608.png]]
				* 커널이 스레드에 대해서 알고 스레드를 관리한다.
				* 따라서 user level thread와 달리, 스레드 테이블이 프로세스에 존재하지 않고 커널에 존재한다.
				* 또한 런타임 시스템이 존재하지 않는다.
				* 스레드 생성 삭제는 커널이 관리하므로 시스템 콜을 통해 작동한다.
				* 만약 스레드가 블록되면 커널은 그 프로세스의 다른 스레드를 수행하거나, 혹은 다른 프로세스의 스레드를 수행할 수 있다.
					* user level 스레드는 무조건 같은 프로세스 내의 스레드만 수행했다.
				* 장점
					* 스레드가 시스템 콜을 하더라도 프로세스가 블록되지 않고, 커널이 다른 실행가능한 스레드를 실행시켜준다.
				* 단점
					* 스레드 연산(생성, 종료)이 빈번하다면 오버헤드가 크다.
			* 3.하이브리드 스레드(Hybrid thread)
				* ![[Pasted image 20231018201212.png]]
				* 이는 커널 스레드를 사용하면서, 각각의 프로세스 내에서 스레드를 다중화 한 것
	* ### 2.3
		* #### Synchronization(동기화)
			* 여러 스레드가 한 자원에 대해 동시 접근하려 한다면 문제가 생긴다.
			* 이를 잘 조절해야한다.
			* interleaved schedules에서 한 자원에 대해  서로 덮어 쓰다보면 잘 못될 수 있다(예로 통장 계좌 예로 5000원 있는데 여기서 3000원쓰고 저장하려는 사이에 2000원 추가한다면, 결론적으로 2000원밖에 없다. 2000천원 추가한게 무시된다.)
		* #### Race condition(경쟁 조건)
			* 위와 같이 타이밍에 의존하여 결과가 달라지는 것을 race condition이라 한다.
			* 즉 잘 될 때도 있고, 잘 안 될 때도 있어 찾기 힘든 버그이다.
			* 문제가 되는 것들
				* local variable은 지역적이라 문제가 되지 않는다.
				* groval variable은 공유되므로 문제가 될 수 있다. 즉 동기화 필요하다.
				* dynamic objects(heap)등은 공유되므로 문제가 될 수 있다. 즉 동기화 필요하다.
		* #### Critical Region(임계구역)
			* 공유 메모리를 접근하는 프로그램 부분을 임계구역이라고 한다.
			* 임계구역의 동시 접근을 막으려면 상호배제(**mutual exclusion**)이 필요하다. 즉 한 프로세스가 공유 자원을 사용하고 있으면 다른 프로세스가 같은 일을 하지 못하도록 막는 것이다.
			* #### 임계구역을  해결하기 위한 네 가지 조건
				* 조건1. mutual exclusion
					* 두 프로세스가 동시에 임계구역에 있는 일은 없어야 한다.
				* 조건2. 
					* cpu의 개수나 속도에 어떤 가정도 하지 않는다.
				* 조건3. progress
					* 임계구역 외부에서 실행하고 있는 프로세스는 다른 프로세스를 블록(멈추게 하는 것)시켜서는 안된다.
						* 예로 busy waiting에서 이 문제가 발생하며 아래에 다시 나온다.
				* 조건4. no starvation
					* 임계구역은 집입하기 위해 무한히 기다리는 프로세스가 없어야 한다.
		* #### 바쁜 대기(busy waiting)를 이용한 상호배제
			* ##### 인터럽트 끄기
				* 한 프로세스가 임계구역을 들어가면 인터럽트를 끄는 것이다.
				* 인터럽트를 끄면 클럭 인터럽트도 발생하지 못하여, 임계구역을 변경하는 동안에 프로세스가 인터럽트에 의하여  중간에 종료되면 변경을 다 마치지 못 한 상태에서 종료되었기에 문제가 발생한다.
				* 문제 
					* 유저에게 인터럽트 끄는 권한은 준다면, 인터럽트를 다시 안 킬 수도 있고, 그럼 문제가 된다.
					* cpu가 두 개 이상이면, 인터럽트 끄는 것은 해당 cpu에게만 영향을 주기에, 다른 cpu가 임계구역을 동시접근할 수 도 있다.
					  
			* ##### 락 변수(lock variable)
				* 공유되는 락 변수를 통해 0이면 임계 구역이 비었고, 1이면 임계구역에 어느 프로세스가 존재함을 인지.
				* 문제점
					* mutual exclution, 즉 조건1을 달성 못한다.
					* A가 락 변수 0임을 발견했을때(즉 if(criticalRegion == 0))
					* B가 락 변수 확인 후, 1로 설정 후 임계구역을 들어간다면
					* A는 IF문을 이미 체크했기에 1로 설정하고 같이 들어간다.
					* 이는 이중체크를 해도 의미 없는 게 또 그 상황에 다른 프로세스가 끼어들 수 있기에.
					  
			* ##### 엄격한 교대
				* ![[Pasted image 20231018211324.png]]
				* while문을 통해 자기 차례가 될 때까지 무한히 기다린다.
				* tunr은 임계구역에 들어가는 순번이다.
				* 즉 turn이 1이면 a가 임계구역에 들어가서 마치고 turn을 1로 바꾼다.
				* 그럼 b가 들어가서 turn을 0으로 바꾸고, 그럼 또 a가 들어간다.
				* 문제:
					* 만약 b가 일이 없다면
					* a가 들어가고 나올 때 1로 바꿨음에도
					* b는 일이 없어서 0으로 바꿔주지 못한다.
					* 그럼 a도 b도 모두 일을 못하게 된다.
					
					* 이 문제를 보면 한 임계구역 밖의 프로세스가 다른 프로세스 일을 못하게 막는다. 조건 3에 위반된다.
				* ##### busy waiting(바쁜 대기)
					* 변수가 특정 값이 될 때까지 계속해서 검사하는 것
					* ##### spinlock
						* 바쁜 대기를 사용하는 락
						  
						  
			* ##### TSL(TEST and set LOCK) 명령
				* 이는 메모리에 LOCK이라는 값을 사옹하며, 이 워드를 읽고, 값을 저장하는 연산동안에 메모리 버스를 잠가, 메모리 동시 접근을 못하게 한다. 
					* 참고로 여기서 메모리 버스를 잠그는 것하고 인터럽트를 끄는 것은 다르다.
					* 인터럽트를 꺼도, 다른 일을 처리하고 있던 io는 io를 마치고 메모리에 접근할 수도 있다.
					* 반면에 메모리 버스를 잠가버리면 다른 처리기도 메모리에 접근 못한다.
				* ![[Pasted image 20231018213631.png]]
					* enter_region
						* TSL명령은 LOCK값을 REGISTER로 가져오고, 메모리의 락값을 1로 설정한다
							* 여기서 가져오고, 1로 설정하는 것이 atomic하게 돌아간다.
								* 다른 프로세스가 접근 못하므로
							* 여기서 1로 설정하는 이유는 만약 기존 LOCK 값이 1이 었다면, 어쩌피 안변한 것이고,
							* 만약 LOCK값이 0이었으면 빨리 바꾸고 내가 들어가야 하므로
						* CMP(compare) 명령을 통해 레지스터값이 0인지 확인한다.
						* 다음에 JNE(jump not equal)을 통해 0이면 다시 enter로 가며 busy waiting을 한다.
						* 0이 아니면 임계구역 처리를 한후 RET(return)한다.
					* leave_region
						* LOCK을 0으로 설정한다.
						* return한다.
				* ##### XCHG(exchange)
					* ![[Pasted image 20231018214347.png]]
					* 이 코드는 위랑 동일하다.
						*  REGISTER값을 1로 설정한 후
						* XCHG(exchange)를 통해 LOCK에는 1을 넣고, REGISTER에 lock값을 가져온다.
				* TSL(XCHG)의 문제
					* 우선순위 역전 문제(priority in-version problem)
						* 만약 B가 임계구역에서 처리하고 있다가
						* context switching으로 우선순위가 높은 A로 넘어갔고
						* A가 임계구역을 들어갈려 했으나, LOCK 변수를 보고 못들어간다.
						* 그럼 B가 임계구역을 못 끝내고 계속 A만 실행된다. 무한루프에 빠진다.
						  
			* 위들은 모두 바쁜 대기를 이용해야 한다는 단점이 있다.
				* 바쁜 대기는 항상 우선순위 역전문제를 가지고 있고 이를 해결하기 위해 sleep and wakeup이 나왔다.
		* #### Sleep and Wake
			* sleep
				* 호출자가 볼록 상태로 만드는 시스템 호출, 즉 스스로 잠
				* 다른 프로세스가 호출자를 깨워줄떄까지 블록된다
			* wakeup
				* 깨울 인자를 하나 가지고 있고, 이 인자를 깨운다.
			* 둘 모두 특정 메모리를 가리키는 하나의 인자를  가지며, 이 주소를 통해 sleep and wakeup을 연계시킨다.
			  
			  * ![[Pasted image 20231018215712.png]]
				  * 이는 생산자 소비자 문제이고 이를 통해서 슬립엔 웨이크를 볼 수 있다.
				  * 문제 
					  * 1. cpu성능 차이
						  * 생산자와 소비자가 모두 count를 공유하면서 생긴다.
						  * 생산자가 count = N임을 확인하는 사이에
						  * 소비자가 N을 모두 소비하고 sleep한다.
						  * 생산자는 슬립하면서 모두 슬립하게 된다.
					  * 2. race condition
						  * item을 공유하므로 동시 consume, insert하면 문제 생긴다.
					  * 3. race condition
						  * count에 동시접근
						    
		  * #### 세마포어
			  * 이는 변수형이고 wakeup이 저장되지 않은 0값, 혹은 한개 이상의 wakeup이 대기 중인 양의 값을 가지 수 있다.
			  * atomic action(원자적 행위)
				  * 이는 행동을 분할할 수 없이 반드시 함께 일어나야한다.
				  * 예를 들어 A->B->C라는 행위가 일어난다면
				  * A->B 행위를 하고 C를 다른 일 먼저하고 처리할 수 없다.
				  * 반드시 이어서 이루어져야 한다.
			  * 세마포어에 대해서는 두 개의 연산이 있다.
				  * down
					  * 세마포어가 0이면, down 수행을 완료하지 않고,즉시 sleep에 들어간다.
					  * 세마포어가 1이상이면, 값을 1내린다.
					  * 값을 검사하고, 변경하고, 잠드는 동작은 모두 atomic 하게 이루어진다.
				  * up
					  * 세마포어가 0이었으면 다른 프로세스를 깨우고 0 유지
					  * 아니면 1을 늘린다.
					  * 이 또한 atomic하게 이루어 진다.
				  * 즉 운영체제에서 atomic을 이루게 할려면, up 혹은 down을 진행하는 동안에는 운영체제 인터럽트를 끄고 세마포어를 검사 변경한다.
				  * 다중 cpu인 경우에는 세마포어는 LOCK변수에 의하여 보호받고 TSL, XCHG 명령어를 사용하여 한순간에 하나의 cpu만 세마포어에 접근할 수 있도록 한다.
			* ![[Pasted image 20231019203049.png]]
			* 여기서 중요한 것은 생산자한테 empty는 위에 있고 소비자한테, empty는 아래에 있어 서로 반대에 있다는 것이다. 그래서 생산자가 empty가 0일때  슬립하더라도 소비자가 일을 마치고 empty를 늘려 소비자가 일을 마친 다음에 생산자가 깨어난다.
			* 데드 락(dead lock)
				* 만약 서로 조금만 위치가 바뀌어도 race condition이 발생하게 된다. 이를 데드락이라고 한다.
				
			  * 세마포어의 종류
				  * binary semaphore(이진 세마포어), 뮤텍스(mutex)
					  * 0, 1로만 상태를 나타낸다.
					  * 기본 1로 세팅되어 있다.
					  * 임계구역을 진입할 때 down 나올때 up
					  * 상호 배제를 위해 사용된다.
				  * counting semaphore
					  * 이는 동기화(synchronization)를 위해 사용된다.
					  * 즉 race condition을 해결 해준다.
			* #### Mutex(뮤텍스)
				* ![[Pasted image 20231019010749.png]]
				* 여기선 0이면 unlock 상태, 1이면 lock 상태이다.
				* mutex_lock은 lock상태이면 sleep하고 unlock이면 빠져나가서 임계구역을 들어갈 수 있게 한다.
				* JZE는 jump if zero이며 ok 이므로 ok: 로 점프한다.
			* \# 참고로 thread_yield는 사용자 공간(프로세스)내에서 스레드 스케줄러를 호출 하기에,  세마포어는 커널을 호출하지 않는다.
				* 커널이 필요 없다는 게 아니다. 세마포어 계산 과정에서 커널에서 락 값을 가져오는 것은 맞다.
			* \# 위는 프로세스들이라도 적어도 공유 메모리가 있다는 가정으로 사용하는 것이다. 만약에 공유 메모리가 없다면, 
				* 공유 자료구조를 사용하여 시스템 콜로만 접근하게 하거나, 
				* 자신의 주소공간 일부를 다른 프로세스도 접근가능하게 하거나
				* 공유 파일을 사용하는 방법이 있다.
				  
				  
			* 세마포어의 장점
				* busy waiting을 하지 않아, 연산이 매우 작다.(성공하던가 잠들던가)
				* 스레드의 경우 busy waiting을 사용할 경우, 바쁜 대기를 하여도 다른 스레드로 전환될 수 없으므로(clock interrupt가 없으므로) 무한 루프에 빠지게 된다. 하지만 mutex를 사용하면 thread_yield를 통해 다른 스레드에 양보하므로  문제가 없다.
					
			* 세마포어를 사용하는 경우, 반드시 깨어났을 때 문장을 계속하는 게 아니라 다시 자신의 조건을 확인해야한다. 그 사이에 변화가 있을 수 있기 떄문이다.
			  
			* ##### 조건 변수(conditional variable)
				* 조건변수는 스레드가 특정 조건이 충족될 때까지 대기하고, 다른 스레드가 그 조건을 충족시키면 깨어나 동작할 수 있도록 하는 메커니즘을 제공합니다.
				* 즉 뮤텍스는 임계구역을 하나만 들어가도록 하며, 조건 변수는 대기하고 깨우는 것을 이용한다.
				* 조건 변수는 이전을 기록하고 있지 않다, 즉 세마포어 처럼 signal을 누적 시킬 수 없고, 아무도 대기하고 있지 않은 조건 변수에 대해 signal이 수행되면 signal은 영원히 사라진다. singal을 불러야 한다면 이는 wait가 수행되었어야 한다.
				* 예로 조건 변수 x가 있다고 하면
					* x.wait()의 경우
						* 이 함수를 호출한 프로세스는 대기
					* x.signal()의 경우
						* x.wait()을 호출한 프로세스중 하나를 깨운다. 만약 대기중인 프로세스가 없다면 아무 일도 일어나지 않는다. 즉 signal이 사라진다.
				* 세마포어의 경우 변수를 변경하는 데, 이는 변경하는 게 아니라, 자고 깨는 동작만 수행
				* 필요한 경우 상태변수(state variable)을 사용하여 프로세스 상태를 파악하고 관리할 수 있다.
		* ### Monitor
			* 기존 세마포어는 down 위치가 하나라도 바뀌면 전체적으로 예기치 못한 오류가 발생할 수 있다.
				* 이러한 문제점을 해결한 것.
			* 모니터란 특별한 형태의 모듈,패키지에 모아진 자료구조,변수,프로시듀어의 모음이다.
			* 이 곳에는 단 하나의 프로세스만이 한 순간에 모니터에서 활동할 수 있다.
			* 프로세스는 원할 때 모니터를 호출할 수 있지만, 모니터 안의 자료는 접근 불가하다.
			* 한 프로세스가 모니터를 호출하였는데, 다른 프로세스가 들어가 있다면  그 프로세스는 중단된다.
			* 모든 언어가 모니터를 지원하지는 않는다. 예로 c는 모니터를 지원하지 않는다.
			
			* ##### wait and signal
				* 모니터에는 프로세스가 더 이상 진행할 수 없을 때 대기하는 방법이 필요하다.
				* wait는 어떤 조건 변수(conditon variables) 호출한 프로세스를 대기하게 만들어, 모니터에서 나오도록 해, 다른 프로세스가 모니터로 접근 할 수 있게 해준다.
				* signal을 통해 파트너 프로세스를 깨울 수 있다
				* 이 후에 어떤 프로세스를 진행할 것인가 규칙이 필요하다. 이게 모니터의 종류
			* ##### 모니터의 종류
				* HOARE 모니터
					* signal로 프로세스가 깨어내면, 모니터에서 진행 중인 프로세스 내리고, 깨어난 프로세스 실행
					* 호러 스럽게 바로 바꿔
				* Hansen 모니터
					* signal을 프로시듀어 마지막에만 사용되게 함.
				* Mesa 모니터
					* signal을 보낸 프로세스가 계속 진행하고, 이 프로세스가 빠져 나가면 깨어난 프로세스 실행
					* 진행중인 건 "메사"에 열정적이라 계속 진행
			* 모니터 사용 예시
				* ![[Pasted image 20231019135042.png]]
				* full, empty는 조건변수로 사용되어, 상태가 변하지 않고, wait, signal을 사용한다.
				* count는 상태변수로 현재 몇개의 item이 버퍼에 있는 지 알려준다.
				* 여기서 item은 지역변수이고, insert, remove는 모니터밖에 존재한다.
				* 여기서 약간의 문제는 wait에서 벗어났을 때 다시 체크를 안한다는 것이다. 여기서 while문을 사용하면 좋다,
				* wait가 되면 조건변수는 조건동기큐에 들어가서 불리기를 기다린다.
				* 조건변수는 모니터 안에서만 접근 가능하다.
			* 모니터 장점
				* 임계구역에 대한 상호배제를 처리 해준다. 즉 race condition을 해결해준다.
				* 기존 sleep and wake와 코드는 유사하지만, 문제가 없다.
			* 모니터 단점
				* 결국 이는 여러 cpu가 공유메모리를 필요로 한다. 그래서 분산환경에서는 서로 메모리를 공유하지 못하므로 사용하지 못한다.
				* 특정 언어에서만 사용가능하다.
				* 이를 해결한 게 메지지 패싱
				  
		* ### 메세지 패싱
			* 이는 send와 receive라는 시스템 콜을 이용하여 프로세스간의 통신을 사용한다.
			* ![[Pasted image 20231019191342.png]]
				* send는 목적지를 명시하며
				* receive는 수신할 곳을 명시한다. 만약 메세지가 안 오면 메시지가 도착할 때까지 대기한다.
				* 메세지는 네트워크상에서 사라질 수 있다.
					* 따라서 수신자는 메세지를 받으면 응답 메세지를 전송하여 합의에 도달한다.
					* 송신자가 지정된 시간동안 응답 메세지를 못받으면 재전송한다.
				* 만약 응답메세지가 사라진다면
					* 이는 메세지에 시퀀스번호를 넣어 문제를 해결한다.
					* 메세지에는 시퀀스 번호를 붙인다.
					* 같은 내용이면시퀀스는 같다
					* 따라서 응답메세지가 사라져서, 다시 전송을 하여도 수신자는 시퀀스 번호가 중복 됨을 인식해 무시한다.
			* ![[Pasted image 20231019192013.png]]
			* 소비자가 N개의 빈 메세지를 보내면,
			* 생산자는 아이템을 생산하여 받은 빈 메세지에 채워, 보낸다.
			* 전체 총 N개의 메세지가 유지된다.
			* 버퍼링
				* 각자의 메일 박스가 존재하며, 소비자의 메일 박스가 꽉 차면, 생산자는 메일박스에 공간이 생길 때까지 대기한다.
			* 랑데뷰(rendezvous) 
				* 이는 버퍼링 없이, send가 호출되면, receive올 때까지 기다리고, 오면 바로 전송
				* 반대로 receive가 먼저 호출되면, send가 호출될때까지 대기
				* 즉 한번에 receive, send가 같이 쓰이는 것이다.
				* 이는 메세지를 버퍼링(박스에 대기)하지는 않지만, 유연하지 못하다.
			* ### 장벽(barrier)
				* 일종의 장벽이 있어, 모든 프로세스가 장벽에 도착할 때까지 먼저 도착한 프로세스는 대기
				  
	* ## 2.4 스케줄링
		* 스케줄러
			* 커널 안에서 다음에 실행할 프로세스를 결정하는 운영체제의 일부
		* cpu 바운드와 io 바운드
			* cpu 바운드
				* cpu 바운드는 프로세스의 대부분의 시간을 계산을 하는 데 사용한다. cpu버스트(cpu 사용)이 크다.
			* io 바운드
				* io 바운드는 프로세스의 대부분의 시간을 io를 기다리는 데 사용되며, cpu 버스트가 짧다. io바운드는 cpu버스트가 작아서 io바운드이다.
			* 요즘은 cpu가 성능이 좋아져서 cpu바운드가 짧아져, 대부분 io바운드 프로세스가 많다. 여기서 핵심은 io바운드 프로세스는 실행을 가능하면 빨리 실행시켜, io가 많은 일을 할 수 있도록 하는 것이다.
		* 스케줄러가 필요한 4가지 경우
			* 1. fork
				* 부모프로세스가, 자식 프로세스를 생성할 경우 둘다 레디큐로 들어가기에 어떤 프로세스를 실행시킬 지 선택해야 한다.
			* 2. io interrupt or clock interrupt
				* io 인터럽트(io가 일을 마쳤다)가 발생하였을 때 블록된 프로세스와, 현재 진행중이던 프로세스 중 선택해야한다.
			* 3. exit
				* 프로세스가 종료되었을 때 다음에 대기중이던 프로세스중 선택하여야 한다.
			* 4. process block
				* 세마포어, 혹은 다른  일로 인해 프로세스가 대기해야 하면 다른 프로세스를 선택해야 한다.
					* 참고로 A프로세스가,  B프로세스가 임계구역을 나오기를 기다리고 있다면 B프로세스 먼저 실행하고 , 그 다음 A프로세스가 올 수 있도록 해야한다. 하지만 스케줄러는 일반적으로 이런 정보를 가지고 있지 않다.
		* #### 스케줄링 알고리즘
			* ##### 비선점(nonpreemptive)
				* 어떤 프로세스는 자신의 프로세스를 마칠 때까지 방해받지 않고 계속 처리한다.  강제 중지 시킬 수 없다.
			* ##### 선점(preemptive)
				*  최대 값으로 정해진 시간(퀀텀)을 넘게 작업하지 못하도록 한다.
				* 즉 클록 인터럽트가 발생하여 스케줄러가 cpu제어를 가져온다.
		* #### 스케줄러 시스템의 세 가지 환경
			* ##### 1. 배치(batch)
				* context switch를 최소화하는 시스템
				* 주로 비선점적(nonpreemtive)시스템이나, 긴 퀀텀을 가진 선점적 시스템에 사용된다.
				* 장점
					* 이는 문맥교환(context switch)를 줄여주어 성능을 향상시킨다.
					* 또한 공평하다.
			* ##### 2. 대화식(interaction)
				* 반응 속도가 중요하므로, 선험적(preemptive)을 사용한다.
			* ##### 3. 실시간(real-time)
				* 이건 반드시 데드라인을 맞춰야하는 시스템.
				* 이 시스템은 제약이 존재하여, 스스로 자신이 오래 일 할 수 없는 것을 알기에 스스로 필요한 일만 하고 cpu를 반납한다. 따라서 의외로 선점이 필요없다.
				  
			* #### 스케줄링 알고리즘의 목표
				* 모든 시스템에서
					* fairness(공평함)
						* 모두가 공평한 몫 cpu를 할당받아야 함
						* 똑같은 게 아님, 필요한 만큼 받는 것.
					* policy enforcement(정책 집행)
						* 정책은 예외없이 집행 되어야 한다.
						* 예로 안전관리 프로세스가 필요하다면 시간이 늦어지더라도 반드시 집행해야한다.
					* balance
						* 모든 시스템의 이용률이 좋아야 한다.
						* 즉 cpu가 일하는 동안, io가 쉬는 것은 좋지 않기에
						* cpu바운드 프로세스 io바운드 프로세스를 번갈아 작업
				* batch의 목표
					* 성능(throughput)
						* throughput은 주어진 시간동안 얼마나 많은 일을 하는가
						* 주어진 시간동안 최대한의 작업을 수행해야함
					* 반환시간(turnaround time)
						* turnaround time은 특정 작업이 주어지고 제출되는데까지 걸린 시간
						* 작업이 주어지고 제출까지 시간 최소화
					* cpu이용률
					  
					* throughput이 좋다고 반드시 turnaroundtime이 좋은 것은 아니다.
						* 예로 짧은 시간이 걸리는 작업만 많이 한다면 throughput은 좋아지겠지만, 이에 밀려서 작업을 못하는 긴 시간이 걸리는 작업은 turnaround time이 무한정 길어진다.
				* interactive(대화식)의 목표
					* 응답시간
						* 반응속도가 빨라야함
							* 즉 사용자가 컴퓨터랑 대화할 때 쓰이는 것은(창열기 등) 백그라운드 작업보다 먼저 수행되어야한다
					* 비례성(proportionality)
						* 이는 오래걸린다고 생각되는 일은 오래해도 되지만
						* 짧은 시간이 걸릴거라고 예상되는 일이 오래되면 화남
				* real time의 목표
					* 마감시간
						* 데드라인을 맞처야함
					* 예측 가능
						* 시간 예측이 가능해야 마감시간을 맞춤
						  
		* ### 배치 시스템의 스케줄링
			* 선입선출(FIFO,FCFS)
				* 단점
					* 긴 시간을 소모하는 프로세스 뒤에 짧은 시간을 소모하는 프로세스가 존재하면 시간이 많이 걸린다.
					  
			* 최단작업우선(shortest job first, SJF)
				* 실행시간이 가장 짧은 최단 작업들을 먼저 선택한다.
				* 주의
					* 모든 작업의 시간을 예측할 수 있어야 한다.
					* 모든 작업이 동시에 들어왔을 경우에만 최소시간이 보장된다.
					  
			* 최단잔여시간우선(shortest remaining time next, SRTN)
				* 이건 작업이 퀀텀단위로 수행된다고 했을 때
				* 스케줄링 될 때마다, 그 때 잔여시간이 제일 짧은 작업을 수행한다.
				  
				  
		* ### 대화식 시스템의 스케줄링
			* 라운드 로빈 스케줄링(Round Robin Scheduling)
				* 프로세스들은 리스트로 관리되며, 주어진 퀀텀시간이 다 되면 리스트 뒤로 들어간다.
				* 여기서 퀀텀 시간이 중요한데
					* 퀀텀시간이 너무 짧으면, 많은 context switch시간을 요구하기에 비효율적이며
					* 퀀텀시간이 너무 길면, 대화식 시스템의 장점이 없어진다. 프로세스가 다 자기할일을 하고 끝내기에
			* 우선순위 스케줄링(priority scheduling)
				* 우선순위가 높은 프로세스 먼저 작업할 수 있도록한다.
				* 허나 우선순위가 높은거만 계속 작업하면 한 프로세스만 계속 작업할 수 있다.
				* 이에 대해
					* 1. 우선순위가 높은 프로세스가 계속 진행될 수 있으므로, 클록인터럽트마다 현재 실행중인 프로세스에 대한 우선순위를 낮춘다.
					* 2. 프로세스가 퀀텀을 모두 사용한다면 다음으로 우선순위 높은 프로세스를 할당한다.
					* 3. io 바운드 프로세스를 높은 우선순위를 준다.
						* 이를 위해서 할당된 시간에서 소모한 시간을 계산하여 1/f를 통해 우선순위를 할당한다. 여기서 f는 50의 시간중 1을 소모하였으면 1/50이다. 즉 1/f를 통해 50이라는 우선순위를 갖는다.
					* 4. 우선순위 클래스
						* ![[Pasted image 20231019214459.png]]
						* 즉 우선순위 4인 프로세스들을 라운드로빈으로 처리하고 비었을 때 우선순위 3을 라운드로빈으로 처리한다.
						* 이는 starvation문제를 발생시킬 수도 있다.
			* 다단계 큐
				* 우선순위 클래스이나 조금 다르다.
				* 이는 우선순위가 높은 큐는 적은 퀀텀시간을 할당하며
				* 우선순위가 낮은 큐는 큰 시간을 할당한다.
				* 한 프로세스가 퀀텀시간을 다 사용하면 우선순위를 한 단계 낮춘다.
				* 이를 통해서 짧은 cputime을 필요로 하는 io바운드 프로세스와, 우선순위는 낮지만 한번 처리하면 긴 cpu버스트를 필요로 하는 cpu바운드 프로세스간의 균형이 맞춰졌다.
				  
			* 보장 스케줄링(guaranteed scheduling)
				* 이는 n개의 프로세스가 있으면 각자 1/n만큼은 보장하는 것
				* 방법은
					* 각 프로세스가 주어진 cpu time과,실제로 사용한 cputime을 나눈다.
					* 즉 ![[Pasted image 20231019215629.png]]
					* 이 값이 작으면 우선순위 배정된다.
					* 왜냐하면 이 값이 작으면 자기해야할 만큼 못쓴거기에
			* 복권 스케줄링(lottery scheduling)
				* 프로세스들에게 티켓을 배분하고, 뽑기를 통해 프로세스를 진행시키는 것
				* 장점
					* 티켓을 보유한 비율만큼 할당될 확률이 결정된다.
					* 결국 마지막에 가면 반드시 프로세스는 작업에 들어간다(starvation이 없다)
					* 티켓을 교환, 즉 양도할 수 있다. 따라서 한 프로세스가 자신이 필요로 하는 프로세스에게 티켓을 몰아줘서 그 프로세스가 빨리 수행되도록 할 수있다.
					  
			* 공평-몫 스케줄링
				* 지금까지는 프로세스의 주인과 무관하게 스케줄링되었다.
				* 하지만 A가 전체프로세스의  90%, B가  10%를 사용한다면 A한테 너무 치우치게 된다.
				* 따라서 프로세스의 소유자를 고려한다.
		* ### 실시간 시스템에서 스케줄링
			* 시스템에는
				* 경성 실시간(hard real-time)
					* 반드시 마감시간을 지켜야 한다.
				* 연성 실시간(soft real-time)
					*  때때로 마감시간을 지키지 않을 수있다.
			* 또한 이벤트는 두가지가 존재한다.
				* 주기적(periodic)
					* 즉 시스템이 응답해야 할 이벤트가 주기적인다.
				* 비주기적(aperiodic)
			* 시스템이 프로세스들을 모두 처리할 수 있는 지 확인할 필요가있다.
				* ![[Pasted image 20231019220937.png]]
				* 이를 만족하면 스케줄가능(schedulable)하다고 한다.
				* P는 주기이고, C는 소모시간이다.
				* 왜냐면  한 프로세스가 5초동안 2를 소모한다하고
				* 다른 프로세스가 5초동안 3을 소모한다고 하면
				* 이를 합치면 2/5 + 3/5 로 1이며, 즉 5초동안 풀로 돌아가는 꼴이므

